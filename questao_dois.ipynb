{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3679c8b4",
   "metadata": {},
   "source": [
    "# Projeto de Previsão de Falha\n",
    "\n",
    "**Autor:** Lucas Porto  \n",
    "**Desafio:** Data Science - Meli  \n",
    "**Objetivo:** Documentar a arquitetura e regras de negócio do sistema de previsão de falhas\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d64d61",
   "metadata": {},
   "source": [
    "## Visão Geral do Projeto\n",
    "\n",
    "### Desafio proposto\n",
    "\n",
    "#### Descrição\n",
    "Os armazéns no mercado livre possuem uma frota de máquinas que transmitem diariamente medidas sobre seu status e funcionamento.\n",
    "As técnicas de manutenção preditiva são projetadas para ajudar a determinar a condição do equipamento de manutenção em serviço para prever quando a manutenção deve ser realizada.\n",
    "Esta abordagem promete economia de custos em relação à manutenção preventiva de rotina ou baseada no tempo, porque as tarefas são executadas apenas quando justificada E m média uma interrupção por falha custa 4x a mais do que uma interrupção preventiva.\n",
    "O arquivo \"full_devices.csv\" possui os valores diários de 9 atributos dos dispositivos ao longo do tempo e a coluna que você está tentando prever é chamada de 'failure' com o valor binário 0 para nenhuma falha e 1 para falha, a coluna do dispositivo possui o id do dispositivo.\n",
    "\n",
    "\n",
    "### Entregável\n",
    "O objetivo é gerar um notebook Jupyter com um modelo para prever a falha do dispositivo antes de uma possível falha. Tente calcular e maximizar a possível economia gerada pelo modelo.\n",
    "\n",
    "\n",
    "### Realizado\n",
    "\n",
    "Para este desafio proposto iremos criar uma regra de negócios para calcularmos o melhor custo benefício entre o custo entre uma falha não detectada e uma manuntenção desnecessária caso prevêssemos errado. Iremos explicar melhor na Regra de Negócio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6850a1b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4451002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import (\n",
    "    load_and_explore_data,\n",
    "    analyze_data_completeness,\n",
    "    analyze_failure_patterns,\n",
    "    verify_data_leakage,\n",
    ")\n",
    "\n",
    "from utils.feature_utils import (\n",
    "    create_features,\n",
    ")\n",
    "\n",
    "from utils.model_utils import (\n",
    "    temporal_cv_evaluation,\n",
    "    create_pipeline_with_metadata,\n",
    ")\n",
    "\n",
    "from utils.pipeline_utils import (\n",
    "    tune_neg_per_pos,\n",
    "    train_evaluate_with_presplit,\n",
    "    apply_optimal_thresholds,\n",
    "    create_final_summary,\n",
    "    save_model_and_metrics,\n",
    "    analyze_feature_importance,\n",
    "    calculate_event_metrics,\n",
    "    select_best_model,\n",
    "    execute_final_model_evaluation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca72e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON_DAYS = 10\n",
    "TAXA_ALERTAS = 0.05\n",
    "C_FN = 100_000\n",
    "C_FP = 25_000\n",
    "COST_RATIO = C_FN / C_FP\n",
    "MIN_PREC_FOR_ROI = C_FP / (C_FP + C_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d4d0a",
   "metadata": {},
   "source": [
    "## Regras de Negócio\n",
    "\n",
    "### Estrutura de Custos\n",
    "\n",
    "A regra de negócio central é baseada na **análise de custo-benefício**:\n",
    "\n",
    "```python\n",
    "# Constantes de custo definidas no projeto\n",
    "C_FN = 100_000    # Custo de uma falha não detectada (False Negative)\n",
    "C_FP = 25_000     # Custo de manutenção desnecessária (False Positive)\n",
    "```\n",
    "\n",
    "### Cálculo de ROI\n",
    "\n",
    "**ROI = (Benefícios - Custos) / Custos × 100%**\n",
    "\n",
    "Onde:\n",
    "- **Benefícios:** Falhas evitadas × Custo da falha\n",
    "- **Custos:** Manutenções desnecessárias × Custo da manutenção\n",
    "\n",
    "### Precisão Mínima e colocamos como se fosse Break-even do projeto\n",
    "\n",
    "```python\n",
    "def min_precision_for_roi(c_fn=100_000, c_fp=25_000):\n",
    "    \"\"\"\n",
    "    Calcula a precisão mínima necessária para atingir break-even\n",
    "    Fórmula: C_FP / (C_FP + C_FN) = 25k / 125k = 20%\n",
    "    \"\"\"\n",
    "    return c_fp / (c_fp + c_fn)  # = 0.20 (20%)\n",
    "```\n",
    "\n",
    "### Ratio de Custos\n",
    "```python\n",
    "COST_RATIO = C_FN / C_FP  # = 4.0\n",
    "# Uma falha não detectada custa 4x mais que uma manutenção desnecessária\n",
    "```\n",
    "\n",
    "### Lógica de Decisão\n",
    "\n",
    "O sistema otimiza para:\n",
    "1. **Maximizar detecção de falhas** (True Positives)\n",
    "2. **Minimizar manutenções desnecessárias** (False Positives)\n",
    "3. **Respeitar orçamento de alertas** (evitar muitos alertas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75053ee",
   "metadata": {},
   "source": [
    "## Carga dos Dados e Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5575517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARREGANDO DADOS ===\n",
      "Shape original: (124494, 12)\n",
      "Colunas: ['date', 'device', 'failure', 'attribute1', 'attribute2', 'attribute3', 'attribute4', 'attribute5', 'attribute6', 'attribute7', 'attribute8', 'attribute9']\n",
      "Removendo 1 duplicatas...\n",
      "Shape após limpeza: (124493, 12)\n",
      "\n",
      "\n",
      "        date    device  failure  attribute1  attribute2  attribute3  \\\n",
      "0 2015-01-01  S1F01085        0   215630672          56           0   \n",
      "1 2015-01-02  S1F01085        0     1650864          56           0   \n",
      "2 2015-01-03  S1F01085        0   124017368          56           0   \n",
      "3 2015-01-04  S1F01085        0   128073224          56           0   \n",
      "4 2015-01-05  S1F01085        0    97393448          56           0   \n",
      "\n",
      "   attribute4  attribute5  attribute6  attribute7  attribute8  attribute9  \n",
      "0          52           6      407438           0           0           7  \n",
      "1          52           6      407438           0           0           7  \n",
      "2          52           6      407438           0           0           7  \n",
      "3          52           6      407439           0           0           7  \n",
      "4          52           6      408114           0           0           7  \n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar e explorar dados\n",
    "df = load_and_explore_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275cc32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124493 entries, 0 to 124492\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   date        124493 non-null  datetime64[ns]\n",
      " 1   device      124493 non-null  object        \n",
      " 2   failure     124493 non-null  int64         \n",
      " 3   attribute1  124493 non-null  int64         \n",
      " 4   attribute2  124493 non-null  int64         \n",
      " 5   attribute3  124493 non-null  int64         \n",
      " 6   attribute4  124493 non-null  int64         \n",
      " 7   attribute5  124493 non-null  int64         \n",
      " 8   attribute6  124493 non-null  int64         \n",
      " 9   attribute7  124493 non-null  int64         \n",
      " 10  attribute8  124493 non-null  int64         \n",
      " 11  attribute9  124493 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(10), object(1)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18043054",
   "metadata": {},
   "source": [
    "### Análise de completude dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704720be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANÁLISE DE COMPLETUDE DOS DADOS ===\n",
      "Total de registros: 124,493\n",
      "Número de dispositivos únicos: 1,169\n",
      "Número de datas únicas: 304\n",
      "Período dos dados: 2015-01-01 00:00:00 at 2015-11-02 00:00:00\n",
      "Registros esperados (todos dispositivos em todas as datas): 355,376\n",
      "Registros atuais: 124,493\n",
      "Diferença: 230,883 registros faltando\n",
      "Taxa de completude: 35.03%\n",
      "Taxa de falhas: 0.0009\n",
      "\n",
      "Dispositivos completos: 27 (2.31%)\n",
      "Datas completas: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# 2. Analisar completude dos dados\n",
    "completeness_info = analyze_data_completeness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef198c",
   "metadata": {},
   "source": [
    "### Análise dos padrões de falhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60e6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANÁLISE DE PADRÕES DE FALHAS ===\n",
      "Distribuição de falhas:\n",
      "  Sem falha (0): 124,387 (99.91%)\n",
      "  Com falha (1): 106 (0.09%)\n",
      "\n",
      "Dispositivos com falhas: 106\n",
      "Dispositivos sem falhas: 1063\n",
      "Taxa média de falhas por dispositivo: 0.0024\n",
      "\n",
      "Dias com falhas: 76\n",
      "Dias sem falhas: 228\n",
      "Taxa média de falhas por dia: 0.0009\n"
     ]
    }
   ],
   "source": [
    "# 3. Analisar padres de falhas\n",
    "device_failures, daily_failures = analyze_failure_patterns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184d219",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Tipos de Features Criadas\n",
    "\n",
    "- **Features Básicas**\n",
    "- Atributos originais (attribute1-9)\n",
    "- Identificação do dispositivo\n",
    "- Timestamp da observação\n",
    "- **Features Temporais**\n",
    "- **Features de Contexto**\n",
    "- **Features de Interação**\n",
    "- **Normalização por Dispositivo**\n",
    "\n",
    "\n",
    "### Resultado Final\n",
    "- **198 features** criadas\n",
    "- **80 features** selecionadas pelo pipeline\n",
    "- **Normalização por dispositivo** para lidar com heterogeneidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d7c24",
   "metadata": {},
   "source": [
    "### Criação de nova target\n",
    "\n",
    "A nova target foi pensada em nos gerar um alerta que permite detectar a falha antes que ela aconteça. Que é o objetivo do nosso trabalho.\n",
    "\n",
    "> \"Se um dispositivo falha no dia D, então nos dias D-1,..., D-10 ele deveria ter recebido um alerta.\"\n",
    "\n",
    "Criamos ele com a função abaixo, isso foi pensado em criamos um alerta de até 10 dias antes do ocorrido.\n",
    "\n",
    "```python\n",
    "def make_early_warning_labels_safe(df, horizon_days=10):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b04d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO FEATURE ENGINEERING ===\n",
      "1. Criando features básicas...\n",
      "2. Criando features de dispositivo...\n",
      "3. Criando features temporais...\n",
      "4. Criando features de contexto...\n",
      "5. Criando features de interação...\n",
      "6. Criando features de tendência...\n",
      "7. Otimizando tipos de dados...\n",
      "8. Aplicando normalização por dispositivo...\n",
      "=== NORMALIZAÇÃO POR DISPOSITIVO (rolling z-score) ===\n",
      "  attribute1: normalizado (rolling=30, min_periods=5)\n",
      "  attribute2: normalizado (rolling=30, min_periods=5)\n",
      "  attribute3: normalizado (rolling=30, min_periods=5)\n",
      "  attribute4: normalizado (rolling=30, min_periods=5)\n",
      "  attribute5: normalizado (rolling=30, min_periods=5)\n",
      "  attribute6: normalizado (rolling=30, min_periods=5)\n",
      "  attribute7: normalizado (rolling=30, min_periods=5)\n",
      "  attribute8: normalizado (rolling=30, min_periods=5)\n",
      "  attribute9: normalizado (rolling=30, min_periods=5)\n",
      "9. Criando target com horizonte de 10 dias...\n",
      "10. Removendo vazamento de target...\n",
      "  Removido 'failure' das features (vazamento de target)\n",
      "=== FEATURE ENGINEERING FINALIZADO ===\n",
      "Shape final: (115576, 198)\n",
      "Número de features: 198\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Engineering +  Target\n",
    "df_features, new_target_col = create_features(\n",
    "    df,\n",
    "    target_col=\"failure\",\n",
    "    forecast_horizon=HORIZON_DAYS,\n",
    "    enable_interactions=True,\n",
    "    max_lags=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e13a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VERIFICAÇÃO DE DATA LEAKAGE ===\n",
      "Analisando 195 features contra target 'early_warn_target'\n",
      "  Nenhuma correlação suspeita detectada\n"
     ]
    }
   ],
   "source": [
    "# 5.  Verificação de data leakage\n",
    "suspicious_features = verify_data_leakage(df_features, new_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06991b",
   "metadata": {},
   "source": [
    "## Pipeline com Metadados\n",
    "\n",
    "Quando trabalhamos com dados temporais, precisamos garantir que:\n",
    "- **Metadados temporais** (datas, dispositivos) sejam preservados\n",
    "- **Split temporal** seja feito antes do processamento\n",
    "- **Features** sejam selecionadas apenas no treino\n",
    "- **Validação** respeite a ordem cronológica\n",
    "\n",
    "\n",
    "1. **Evita Data Leakage**\n",
    "   - Split temporal antes do processamento\n",
    "   - Features selecionadas apenas no treino\n",
    "   - Metadados preservados para validação\n",
    "\n",
    "2. **Preserva Contexto Temporal**\n",
    "   - Datas mantidas para análise temporal\n",
    "   - Dispositivos identificados para cooldown\n",
    "   - Ordem cronológica respeitada\n",
    "\n",
    "3. **Facilita Validação**\n",
    "   - Métricas por evento\n",
    "   - Análise de cooldown\n",
    "   - ROI baseado em falhas reais\n",
    "\n",
    "\n",
    "Separamos os dados temporais em:\n",
    "- **Dados de treino**\n",
    "- **Dados de validação:** separado para otimizaro o modelo\n",
    "- **Dados de validação final (holdout)**: utilizado para validar sem vazamento\n",
    "- **Dados de teste**: para nossa aplicação final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f9d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PIPELINE SEGURO COM METADADOS ===\n",
      "Split temporal:\n",
      "  Train: 90,045 samples\n",
      "  Val: 13,540 samples\n",
      "  Test: 5,589 samples\n",
      "Features disponíveis: 195\n",
      "Aplicando pipeline...\n",
      "Features selecionadas: 80\n",
      "Validação separada:\n",
      "  Modelo: 2,708 samples\n",
      "  Calibração: 10,832 samples\n"
     ]
    }
   ],
   "source": [
    "# 6.  Pipeline com metadados\n",
    "(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val_model,\n",
    "    y_val_model,\n",
    "    X_val_hold,\n",
    "    y_val_hold,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    selected_features,\n",
    "    dates_train,\n",
    "    devices_train,\n",
    "    dates_val_model,\n",
    "    devices_val_model,\n",
    "    dates_val_hold,\n",
    "    devices_val_hold,\n",
    "    dates_test,\n",
    "    devices_test,\n",
    ") = create_pipeline_with_metadata(df_features, target_col=new_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48973ce2",
   "metadata": {},
   "source": [
    "## Validação Cruzada Temporal\n",
    "\n",
    "A **Validação Cruzada Temporal** é uma técnica que simula o cenário real de produção, onde:\n",
    "- **Dados futuros** não estão disponíveis no treinamento\n",
    "- **Ordem cronológica** deve ser respeitada\n",
    "- **Performance** deve ser consistente ao longo do tempo\n",
    "\n",
    "### Implementação de proteção\n",
    "\n",
    "1. **Purge de 7 dias** entre treino e validação\n",
    "2. **Split temporal rigoroso** (não aleatório)\n",
    "3. **Pipeline aplicado** em cada fold\n",
    "4. **Métricas consistentes** entre folds\n",
    "\n",
    "### Sinais de Alerta\n",
    "\n",
    "- **Custo crescente** ao longo dos folds\n",
    "- **Recall decrescente** no tempo\n",
    "- **Alta variabilidade** entre folds\n",
    "- **Performance ruim** em folds recentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d084c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ROLLING ORIGIN CV (n=3) COM PURGE ===\n",
      "Fold 1: cost=392.0 | AP=0.0043 | recall=0.091\n",
      "Fold 2: cost=538.0 | AP=0.0777 | recall=0.574\n",
      "Fold 3: cost=970.0 | AP=0.2122 | recall=0.459\n",
      "Médias: {'fold': 2.0, 'cost': 633.3333333333334, 'ap': 0.09806541993735318, 'recall': 0.37489316719895643}\n",
      "\n",
      "Pipeline:\n",
      "  Train: 90,045 samples (0.0094 failure rate)\n",
      "  Val: 13,540 samples (0.0127 failure rate)\n",
      "  Features selecionadas: 80\n"
     ]
    }
   ],
   "source": [
    "# 7. CV Ttemporal\n",
    "cv_output = temporal_cv_evaluation(\n",
    "    df_features,\n",
    "    target_col=new_target_col,\n",
    "    n_splits=3,\n",
    "    purge_days=7,\n",
    ")\n",
    "cv_results = cv_output[\"cv_results\"]\n",
    "cv_summary = cv_output[\"cv_summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7c86c",
   "metadata": {},
   "source": [
    "Com base nos nossos dados, temos um modelo com custo aumentando com o tempo, variabilizade alta, mas o recall se mantem um valor razoável.\n",
    "\n",
    "Podemos ver que temos drift nos dados e alta variabilidade no tempo devido nosso custo aumentar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffafc3e",
   "metadata": {},
   "source": [
    "## Otimizando o Balanceamento\n",
    "\n",
    "### Criação de parâmetro para otimização\n",
    "\n",
    "O **neg_per_pos** é um parâmetro criado que define quantos **exemplos negativos** (não-falha) usar para cada **exemplo positivo** (falha) durante o treinamento:\n",
    "\n",
    "```python\n",
    "# Exemplo:\n",
    "# neg_per_pos = 8 significa:\n",
    "# - 1 exemplo de falha (positivo)\n",
    "# - 8 exemplos de não-falha (negativos)\n",
    "# - Ratio: 1:8 (12.5% de falhas)\n",
    "```\n",
    "\n",
    "### Por Que Precisamos de Tuning?\n",
    "\n",
    "#### **1. Problema de Classes Desbalanceadas**\n",
    "- **Dados originais**: 0.09% de falhas (106 falhas em 124,494 registros)\n",
    "- **Após early warning**: ~1% de falhas (ainda muito desbalanceado)\n",
    "- **Modelo precisa** de mais exemplos negativos para aprender\n",
    "\n",
    "#### **2. Trade-off Crítico**\n",
    "- **Muitos negativos** → Modelo fica conservador (baixo recall)\n",
    "- **Poucos negativos** → Modelo fica agressivo (muitos falsos positivos)\n",
    "- **Balanceamento ótimo** → Performance máxima\n",
    "\n",
    "\n",
    "### Critérios de Seleção\n",
    "\n",
    "#### **1. Custo de Negócio**\n",
    "- **Custo total** = 4 × FN + 1 × FP\n",
    "- **Objetivo**: Minimizar custo\n",
    "- **Prioridade**: Evitar falhas não detectadas\n",
    "\n",
    "#### **2. Taxa de Alertas**\n",
    "- **Máximo**: 5% dos dispositivos\n",
    "- **Objetivo**: Não sobrecarregar operações\n",
    "- **Balanceamento**: Performance vs. Operacional\n",
    "\n",
    "#### **3. Métricas Técnicas**\n",
    "- **Precision**: > 20% (break-even)\n",
    "- **Recall**: > 60% (cobertura de falhas)\n",
    "- **F1-Score**: Balanceamento geral\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9033e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TUNING NEG_PER_POS ===\n",
      "Testando neg_per_pos=6...\n",
      "\n",
      "=== APLICANDO UNDERSAMPLING ===\n",
      "Dataset original: 90045 amostras | dist: {0: np.int64(89197), 1: np.int64(848)} | rate=0.0094\n",
      "US: 90045 -> 5936 | pos=848 neg=5088 (neg/pos~6.0, antes~105.2)\n",
      "  neg_per_pos=6: custo=232, thr=0.869, alertas=0.5%, precisão=71.4%, método=cost_optimal\n",
      "Testando neg_per_pos=8...\n",
      "\n",
      "=== APLICANDO UNDERSAMPLING ===\n",
      "Dataset original: 90045 amostras | dist: {0: np.int64(89197), 1: np.int64(848)} | rate=0.0094\n",
      "US: 90045 -> 7632 | pos=848 neg=6784 (neg/pos~8.0, antes~105.2)\n",
      "  neg_per_pos=8: custo=204, thr=0.349, alertas=5.0%, precisão=29.4%, método=budget_fallback\n",
      "Testando neg_per_pos=10...\n",
      "\n",
      "=== APLICANDO UNDERSAMPLING ===\n",
      "Dataset original: 90045 amostras | dist: {0: np.int64(89197), 1: np.int64(848)} | rate=0.0094\n",
      "US: 90045 -> 9328 | pos=848 neg=8480 (neg/pos~10.0, antes~105.2)\n",
      "  neg_per_pos=10: custo=237, thr=0.902, alertas=0.5%, precisão=64.3%, método=cost_optimal\n",
      "Testando neg_per_pos=12...\n",
      "\n",
      "=== APLICANDO UNDERSAMPLING ===\n",
      "Dataset original: 90045 amostras | dist: {0: np.int64(89197), 1: np.int64(848)} | rate=0.0094\n",
      "US: 90045 -> 11024 | pos=848 neg=10176 (neg/pos~12.0, antes~105.2)\n",
      "  neg_per_pos=12: custo=239, thr=0.210, alertas=5.0%, precisão=24.3%, método=budget_fallback\n",
      "Testando neg_per_pos=15...\n",
      "\n",
      "=== APLICANDO UNDERSAMPLING ===\n",
      "Dataset original: 90045 amostras | dist: {0: np.int64(89197), 1: np.int64(848)} | rate=0.0094\n",
      "US: 90045 -> 13568 | pos=848 neg=12720 (neg/pos~15.0, antes~105.2)\n",
      "  neg_per_pos=15: custo=251, thr=0.632, alertas=1.0%, precisão=32.1%, método=cost_optimal\n",
      "Testando neg_per_pos=20...\n",
      "\n",
      "=== APLICANDO UNDERSAMPLING ===\n",
      "Dataset original: 90045 amostras | dist: {0: np.int64(89197), 1: np.int64(848)} | rate=0.0094\n",
      "US: 90045 -> 17808 | pos=848 neg=16960 (neg/pos~20.0, antes~105.2)\n",
      "  neg_per_pos=20: custo=232, thr=0.565, alertas=1.6%, precisão=36.4%, método=cost_optimal\n",
      "[tuner] melhor neg_per_pos=8 | custo_val=204.0 | thr_val=0.349 | alertas=5.0%\n"
     ]
    }
   ],
   "source": [
    "# 8. Otimização e Balanceamento\n",
    "best_us = tune_neg_per_pos(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val_model,\n",
    "    y_val_model,\n",
    "    candidates=(6, 8, 10, 12, 15, 20),\n",
    "    max_alert_rate=TAXA_ALERTAS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b630939",
   "metadata": {},
   "source": [
    "Dentro dos parâmetros que selecionamos, tivemos o melhor tunning com: \n",
    "- Distribuição: Negativos x Positivos em 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe57e4",
   "metadata": {},
   "source": [
    "## Treinando os Modelos\n",
    "\n",
    "### **Modelos Selecionados**\n",
    "- XGBoost: XGBClassifier\n",
    "- LGBM: LGBMClassifier\n",
    "- Ensemble entre ambos\n",
    "\n",
    "### **Otimização de Thresholds**\n",
    "\n",
    "Utilizamos dentro do treinamento a seleção do melhor threshold.\n",
    "\n",
    "\n",
    "| Métrica Técnica | Métrica de Negócio | Implementação |\n",
    "|-----------------|-------------------|----------------|\n",
    "| **AUC-ROC** | Capacidade de discriminação | `roc_auc_score()` |\n",
    "| **Average Precision** | Performance em desbalanceado | `average_precision_score()` |\n",
    "| **Confusion Matrix** | **Custo (4×FN + 1×FP)** | `4 * fn + fp` |\n",
    "| **Threshold** | **Orçamento de alertas** | `tune_alert_budget_simple()` |\n",
    "| **Precision** | **Break-even (20%)** | `min_precision=0.20` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73bd25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TREINANDO MODELOS COM CONJUNTOS PR-SPLIT (BUDGET+CALIBRAÇÃO) ===\n",
      "\n",
      "=== UNDERSAMPLING HARD NEGATIVES ===\n",
      "Undersampling hard negatives aplicado: 7632 amostras\n",
      "Scale pos weight: 1.00\n",
      "Train: 7,632 | Val: 2,708 | Test: 5,589\n",
      "\n",
      "=== TREINANDO XGBOOST ===\n",
      "Calibrao time-aware aplicada (XGB).\n",
      "Tuner: Budget...\n",
      "[XGB] fallback - melhor precisão disponível (thr=0.298, alertas=0.3%)\n",
      "XGB | AUC=0.7660 AP=0.1226 thr=0.298 cost=116.0 | CM=[[5552, 4], [28, 5]]\n",
      "\n",
      "=== TREINANDO LIGHTGBM ===\n",
      "Calibrao time-aware aplicada (LGB).\n",
      "Tuner: Budget...\n",
      "[LGB] fallback - melhor precisão disponível (thr=0.350, alertas=1.7%)\n",
      "LGB | AUC=0.8917 AP=0.0900 thr=0.350 cost=132.0 | CM=[[5556, 0], [33, 0]]\n",
      "Ensemble ponderado: XGB=0.464, LGB=0.536\n",
      "[budget tuner] best_alert_rate=1.0% | thr=0.226 | val_cost=294.0 | cm=(np.int64(2611), np.int64(30), np.int64(66), np.int64(1))\n",
      "Ensemble | AUC=0.9017 AP=0.2301 thr=0.226 cost=116.0 | CM=[[5552, 4], [28, 5]]\n",
      "Calculando predições de holdout durante o treinamento...\n"
     ]
    }
   ],
   "source": [
    "# 9. Treinar e avaliar com conjuntos pr-split\n",
    "models_results = train_evaluate_with_presplit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val_model,\n",
    "    y_val_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    min_pr=MIN_PREC_FOR_ROI,\n",
    "    X_val_hold=X_val_hold,\n",
    "    y_val_hold=y_val_hold,\n",
    "    dates_train=dates_train,\n",
    "    devices_train=devices_train,\n",
    "    dates_val=dates_val_model,\n",
    "    devices_val=devices_val_model,\n",
    "    dates_test=dates_test,\n",
    "    devices_test=devices_test,\n",
    "    random_state=42,\n",
    "    apply_balance=True,\n",
    "    neg_per_pos=best_us[\"neg_per_pos\"],\n",
    "    max_neg_cap=50_000,\n",
    "    calibrate=True,\n",
    "    use_alert_budget=True,\n",
    "    alert_budgets=(0.01, 0.015, 0.02, 0.03),\n",
    "    feature_names=selected_features,\n",
    "    selected_features=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4bc3a8",
   "metadata": {},
   "source": [
    "## Aplicação dos Thresholds\n",
    "\n",
    "A função `apply_optimal_thresholds` é a **otimização final** do sistema que:\n",
    "\n",
    "1. **Testa múltiplos orçamentos** de alertas (0.2% a 5%)\n",
    "2. **Encontra thresholds ótimos** para cada orçamento\n",
    "3. **Avalia performance** com métricas de negócio\n",
    "4. **Escolhe a melhor configuração** para produção\n",
    "\n",
    "### Processo de Otimização\n",
    "\n",
    "#### Teste em orçamentos\n",
    "```python\n",
    "for budget in budgets:\n",
    "    # Encontrar threshold que respeita o orçamento\n",
    "    threshold = find_threshold_for_budget(\n",
    "        y_val, \n",
    "        model_proba_val,\n",
    "        target_budget=budget\n",
    "    )\n",
    "    \n",
    "    # Aplicar threshold no teste\n",
    "    y_pred_test = (model_proba_test >= threshold).astype(int)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    cost = calculate_business_cost(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test)\n",
    "    recall = recall_score(y_test, y_pred_test)\n",
    "    alert_rate = y_pred_test.mean()\n",
    "    \n",
    "    # Verificar restrições\n",
    "    if precision >= min_precision and alert_rate <= budget:\n",
    "        results[budget] = {\n",
    "            'threshold': threshold,\n",
    "            'cost': cost,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'alert_rate': alert_rate\n",
    "        }\n",
    "```\n",
    "\n",
    "#### Seleção da melhor configuração\n",
    "```python\n",
    "# Escolher orçamento com menor custo\n",
    "best_budget = min(results.keys(), key=lambda x: results[x]['cost'])\n",
    "\n",
    "# Configuração final\n",
    "best_config = {\n",
    "    'budget': best_budget,\n",
    "    'threshold': results[best_budget]['threshold'],\n",
    "    'cost': results[best_budget]['cost'],\n",
    "    'precision': results[best_budget]['precision'],\n",
    "    'recall': results[best_budget]['recall'],\n",
    "    'alert_rate': results[best_budget]['alert_rate']\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35d79789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "APLICAÇÃO DOS THRESHOLDS ÓTIMOS (min_precision=20%)\n",
      "============================================================\n",
      "Tuner: Budget...\n",
      "\n",
      "XGBoost: thr=0.3000 | budget~1.000% | alertas=0.16% | precisão_test=55.6% | custo=116 | prec_event=20.0% | recall_event=33.3% | ROI=0.0%\n",
      "Tuner: Budget...\n",
      "\n",
      "LightGBM: thr=0.3500 | budget~1.000% | alertas=0.00% | precisão_test=0.0% | custo=132 | prec_event=0.0% | recall_event=0.0% | ROI=0.0%\n",
      "Tuner: Budget...\n",
      "\n",
      "EnsembleAvg: thr=0.2300 | budget~1.000% | alertas=0.16% | precisão_test=55.6% | custo=116 | prec_event=20.0% | recall_event=33.3% | ROI=0.0%\n"
     ]
    }
   ],
   "source": [
    "# 10. Aplicação dos thresholds ótimos com orçamento de alertas\n",
    "models_results = apply_optimal_thresholds(\n",
    "    models_results,\n",
    "    y_val_model,\n",
    "    y_test,\n",
    "    dates_val=dates_val_model,\n",
    "    devices_val=devices_val_model,\n",
    "    dates_test=dates_test,\n",
    "    devices_test=devices_test,\n",
    "    df_features=df,\n",
    "    min_precision=MIN_PREC_FOR_ROI,\n",
    "    c_fn=C_FN,\n",
    "    c_fp=C_FP,\n",
    "    budgets=(\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.004,\n",
    "        0.005,\n",
    "        0.006,\n",
    "        0.008,\n",
    "        0.010,\n",
    "        0.012,\n",
    "        0.015,\n",
    "        0.020,\n",
    "        0.030,\n",
    "        0.050,\n",
    "    ),\n",
    "    horizon_days=HORIZON_DAYS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9a8dd",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Analisamos o feature importance para cada modelo, para analisarmos quais são mais improtantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342d56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANÁLISE DE FEATURE IMPORTANCE ===\n",
      "\n",
      "XGBoost - Top 20 Features:\n",
      "==================================================\n",
      "0.1372 - attribute4_normalized\n",
      "0.0754 - attribute7_ma_3\n",
      "0.0680 - attribute7\n",
      "0.0361 - attribute4_slope_7\n",
      "0.0347 - attribute2_attribute4_sum\n",
      "0.0343 - attribute2_std_14\n",
      "0.0337 - attribute2_lag_2\n",
      "0.0311 - attribute6_lag_3\n",
      "0.0296 - attribute2_lag_3\n",
      "0.0271 - attribute6_ma_14\n",
      "0.0239 - attribute9_lag_7\n",
      "0.0217 - doy_cos\n",
      "0.0203 - attribute2_slope_14\n",
      "0.0181 - attribute6_ma_3\n",
      "0.0165 - attribute4_std_expanding\n",
      "0.0163 - attribute6_lag_2\n",
      "0.0158 - attribute6_ma_7\n",
      "0.0153 - attribute5_lag_1\n",
      "0.0147 - attribute2\n",
      "0.0143 - attribute6_lag_1\n",
      "\n",
      "LightGBM - Top 20 Features:\n",
      "==================================================\n",
      "2.0000 - doy_sin\n",
      "2.0000 - attribute6_lag_1\n",
      "2.0000 - attribute6_lag_2\n",
      "2.0000 - attribute1_std_14\n",
      "1.0000 - attribute2_std_14\n",
      "1.0000 - attribute7\n",
      "1.0000 - week_sin\n",
      "1.0000 - attribute6_lag_7\n",
      "1.0000 - device_obs_so_far\n",
      "1.0000 - attribute5_normalized\n",
      "1.0000 - attribute6_normalized\n",
      "1.0000 - attribute2_attribute4_sum\n",
      "1.0000 - attribute4_slope_7\n",
      "0.0000 - attribute6\n",
      "0.0000 - attribute5\n",
      "0.0000 - attribute1\n",
      "0.0000 - attribute1_lag_2\n",
      "0.0000 - attribute1_lag_1\n",
      "0.0000 - doy_cos\n",
      "0.0000 - day_cos\n",
      "\n",
      "EnsembleAvg - Top 20 Features:\n",
      "==================================================\n",
      "EnsembleRank não tem feature importance individual\n"
     ]
    }
   ],
   "source": [
    "# 11. Analisar feature importance\n",
    "models_results = analyze_feature_importance(models_results, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c41b7",
   "metadata": {},
   "source": [
    "## Calculando métricas por evento\n",
    "\n",
    "A métrica por evento é calculada para ser mais um dos parametros usados na seleção do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "010fb8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MÉTRICAS POR EVENTO ===\n",
      "XGBoost | event_coverage=33.3% | alerts_per_100dev_week=0.79\n",
      "LightGBM | event_coverage=0.0% | alerts_per_100dev_week=0.00\n",
      "EnsembleAvg | event_coverage=33.3% | alerts_per_100dev_week=0.79\n"
     ]
    }
   ],
   "source": [
    "# 12. Métricas por evento\n",
    "models_results = calculate_event_metrics(models_results, df, dates_test, devices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d89a669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SELEÇÃO DO MELHOR MODELO (VALIDAÇÃO HOLDOUT)\n",
      "============================================================\n",
      "\n",
      "COMPARAÇÃO DE MODELOS:\n",
      "        Modelo  AUC-ROC  Custo  Precision  Recall\n",
      "0      XGBoost   0.7660    116     0.3158  0.0571\n",
      "2  EnsembleAvg   0.9017    116     0.3158  0.0571\n",
      "1     LightGBM   0.8917    132     0.0000  0.0000\n",
      "\n",
      "MELHOR MODELO SELECIONADO: XGBoost\n",
      "   Custo: 116\n"
     ]
    }
   ],
   "source": [
    "# 13. Selecionar o melhor modelo usando holdout e métrica de custo\n",
    "best_model_name, best_model_results, comparison_df = select_best_model(\n",
    "    models_results, y_val_hold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f2d5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECUÇÃO FINAL DO MELHOR MODELO: XGBoost\n",
      "============================================================\n",
      "Executando XGBoost...\n",
      "Aplicando calibração...\n",
      "\n",
      "RESULTADOS DO TESTE FINAL:\n",
      "   Modelo: XGBoost\n",
      "   Threshold: 0.3000\n",
      "   Alert Rate: 0.002\n",
      "   Recall: 0.152\n",
      "   AUC-PR: 0.123\n",
      "\n",
      "MÉTRICAS DE NEGÓCIO:\n",
      "   ROI por Evento: 0.0%\n",
      "   Precisão por Evento: 20.0%\n",
      "   Recall por Evento: 33.3%\n",
      "\n",
      "ANÁLISE DE ALERTAS:\n",
      "   Total de Alertas: 9\n",
      "   Taxa de Alertas: 0.16%\n",
      "   Falsos Negativos: 28\n",
      "   Falsos Positivos: 4\n"
     ]
    }
   ],
   "source": [
    "# 14. Execução final do melhor modelo com dados de teste\n",
    "final_test_results = execute_final_model_evaluation(\n",
    "    best_model_name=best_model_name,\n",
    "    best_model_results=best_model_results,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    dates_test=dates_test,\n",
    "    devices_test=devices_test,\n",
    "    df=df,\n",
    "    c_fn=C_FN,\n",
    "    c_fp=C_FP,\n",
    "    horizon_days=HORIZON_DAYS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9e4c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMO FINAL - MÉTRICAS ESSENCIAIS\n",
      "============================================================\n",
      "\n",
      "COMPARAÇÃO DE MODELOS:\n",
      "--------------------------------------------------\n",
      "XGBoost:\n",
      "  ROI por Evento: 0.0%\n",
      "  Precisão por Evento: 20.0%\n",
      "  Recall por Evento: 33.3%\n",
      "  Custo: 116\n",
      "\n",
      "LightGBM:\n",
      "  ROI por Evento: 0.0%\n",
      "  Precisão por Evento: 0.0%\n",
      "  Recall por Evento: 0.0%\n",
      "  Custo: 132\n",
      "\n",
      "EnsembleAvg:\n",
      "  ROI por Evento: 0.0%\n",
      "  Precisão por Evento: 20.0%\n",
      "  Recall por Evento: 33.3%\n",
      "  Custo: 116\n",
      "\n",
      "ANÁLISE DE BREAK-EVEN:\n",
      "------------------------------\n",
      "Precisão mínima para break-even: 20.0%\n",
      "Ratio custo FN/FP: 4.0\n",
      "\n",
      "XGBoost:\n",
      "  Precisão: 20.0% [OK]\n",
      "  ROI: 0.0%\n",
      "\n",
      "LightGBM:\n",
      "  Precisão: 0.0% [FAIL]\n",
      "  ROI: 0.0%\n",
      "\n",
      "EnsembleAvg:\n",
      "  Precisão: 20.0% [OK]\n",
      "  ROI: 0.0%\n",
      "\n",
      "\n",
      "============================================================\n",
      "SALVANDO MODELO E MÉTRICAS - 20251006_100036\n",
      "============================================================\n",
      "Melhor modelo salvo: models\\device_failure_model_xgboost_20251006_100036.pkl\n",
      "Métricas de performance salvas: models\\device_failure_model_metrics_20251006_100036.json\n",
      "Resumo executivo salvo: models\\device_failure_model_executive_20251006_100036.json\n",
      "\n",
      "Melhor modelo e métricas salvos com sucesso!\n",
      "Diretório: models\n",
      "Timestamp: 20251006_100036\n",
      "Arquivos criados:\n",
      "   - device_failure_model_xgboost_20251006_100036.pkl (melhor modelo: XGBoost)\n",
      "   - device_failure_model_metrics_20251006_100036.json (métricas de performance)\n",
      "   - device_failure_model_executive_20251006_100036.json (resumo executivo)\n"
     ]
    }
   ],
   "source": [
    "# 15. Resumo final e métricas de ROI\n",
    "summary = create_final_summary(\n",
    "    models_results,\n",
    "    dates_train,\n",
    "    dates_val_model,\n",
    "    dates_val_hold,\n",
    "    dates_test,\n",
    "    selected_features,\n",
    "    cv_results,\n",
    "    cv_summary,\n",
    "    suspicious_features,\n",
    "    c_fn=C_FN,\n",
    "    c_fp=C_FP,\n",
    "    min_roi=MIN_PREC_FOR_ROI,\n",
    ")\n",
    "\n",
    "save_paths = save_model_and_metrics(\n",
    "    best_model_name=best_model_name,\n",
    "    best_model_results=best_model_results,\n",
    "    selected_features=selected_features,\n",
    "    summary=summary,\n",
    "    final_test_results=final_test_results,\n",
    "    cv_results=cv_results,\n",
    "    cv_summary=cv_summary,\n",
    "    suspicious_features=suspicious_features,\n",
    "    model_name=\"device_failure_model\",\n",
    "    save_dir=\"models\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
